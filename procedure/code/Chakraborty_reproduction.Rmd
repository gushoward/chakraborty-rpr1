---
title: "Chakroborty Repoduction"
author: "Gus Howard"
date: "2025-03-7"
output: html_document
---


# Abstract

Chakraborty (2021) examines the relationship between COVID-19 incidence rates and the percentage of people with disabilities across U.S. counties, considering socio-demographic factors like race, ethnicity, poverty status, age, and sex. Using bivariate correlations and generalized estimating equation (GEE) models, the study finds significant positive associations between COVID-19 rates and socially vulnerable populations. This reproduction study aims to verify Chakraborty’s findings for policy, research, and educational purposes by replicating all analyses, including county-level COVID-19 distributions, statistical correlations, and GEE models. The data and code are publicly available on GitHub, ensuring transparency and accessibility for further study.

## Keywords
COVID-19, Race, Disability

## Study Design

This is a reproduction study to understand the links between race/ethnicity and disability and COVID-19 rates.

## Packages

```{r}
packages <- c(
  "tidycensus", "tidyverse", "downloader", "sf", "classInt", "readr",
  "here", "s2", "pastecs", "tmap", "SpatialEpi", "svDialogs",
  "geepack", "knitr", "kableExtra", "foreign", "broom", "dotwhisker", "dotenv"
)

# load and install required packages
if(!require(groundhog)){
  install.packages("groundhog")
  require(groundhog)
}

if(!require(here)){
  install.packages("here")
  require(here)
}

groundhog.day <- "2025-03-08"
set.groundhog.folder(here("data", "scratch", "groundhog"))
groundhog.library(packages, groundhog.day)
```

# DATA

# Study metadata
Key words: COVID-19, Disability, Race/ethnicity, Poverty, Reproducibility
Subject: Social and Behavioral Sciences: Geography: Geographic Information Sciences
Spatial Coverage: Continental United States
Spatial Resolution: US Counties
Spatial Reference System: Contiguous USA Albers Equal Area projection EPSG:5070
Temporal Coverage: From 1/22/2020 to 8/1/2020
Temporal Resolution: Rates were collected as one temporal unit.

## ACS data
The American Community Survey (ACS) five-year estimate (2014-2018) variables used in the study are outlined in the table below.
Details on ACS data collection can be found at <https://www.census.gov/topics/health/disability/guidance/data-collection-acs.html>

```{r}
 # Query disability demographic data with geographic boundaries

acs <- get_acs(geography = "county",
  table = "S1810",
  year = 2018,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Query poverty and disability data
acs_pov <- get_acs(geography = "county",
  table = "C18130",
  year = 2018,
  output = "wide",
  cache_table = TRUE
)

# Query state geographic data
state <- get_acs(geography = "state",
  year = 2018,
  variables = c("B01001_001"),
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Save query results
saveRDS(acs, here("data", "raw", "public", "acs.RDS"))
saveRDS(acs_pov, here("data", "raw", "public", "acs_pov.RDS"))
saveRDS(state, here("data", "raw", "public", "state.RDS"))
```

## Data Transformations

Initial Study does not include Alaska, Hawaii, or Puerto Rico. Data on people with disabilities in poverty is derived from a different census table (C18130) than data on people with disabilities and age, race, ethnicity, age, and biological sex (S1810). 
```{r}
# transform coordinate system and fix geometries
acs <- filter(acs, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070) %>%
  st_make_valid()

# Remove Alaska, Hawaii & Puerto Rico,
state <- filter(state, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070)

# Join poverty data to disability data
acs <- acs %>% left_join(acs_pov, by = "GEOID")
rm(acs_pov)
```

```{r Preprocess-ACS}
acs_derived <- mutate(acs,
  dis_pct = S1810_C02_001E / S1810_C01_001E * 100,
  white_pct = S1810_C02_004E / S1810_C01_001E * 100,
  black_pct = S1810_C02_005E / S1810_C01_001E * 100,
  native_pct = S1810_C02_006E / S1810_C01_001E * 100,
  asian_pct = S1810_C02_007E / S1810_C01_001E * 100,
  other_pct =
    (S1810_C02_008E + S1810_C02_009E + S1810_C02_010E) / S1810_C01_001E * 100,
  non_hisp_white_pct = S1810_C02_011E / S1810_C01_001E * 100,
  hisp_pct = S1810_C02_012E / S1810_C01_001E * 100,
  non_hisp_non_white_pct =
    (S1810_C02_001E - S1810_C02_012E - S1810_C02_011E) / S1810_C01_001E * 100,
  bpov_pct = (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100,
  apov_pct = (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100,
  pct_5_17 = S1810_C02_014E / S1810_C01_001E * 100,
  pct_18_34 = S1810_C02_015E / S1810_C01_001E * 100,
  pct_35_64 = S1810_C02_016E / S1810_C01_001E * 100,
  pct_65_74 = S1810_C02_017E / S1810_C01_001E * 100,
  pct_75 = S1810_C02_018E / S1810_C01_001E * 100,
  male_pct = S1810_C02_002E / S1810_C01_001E * 100,
  female_pct = S1810_C02_003E / S1810_C01_001E * 100
)

# select only relevant geographic identifiers and derived percentages
acs_derived <- acs_derived %>%
  select(
    fips = GEOID,
    statefp = STATEFP,
    county = NAME.x,
    county_st = NAME,
    contains("pct")
  )
```

## COVID Data
The data includes an estimate of the total population (POP_ESTIMA) and confirmed COVID-19 cases (Confirmed). The COVID-19 case data expresses cumulative count of reported COVID-19 from 1/22/2020 to 8/1/2020. Versions of the data can be found at the John Hopkins CCSE COVID-19 Data Repository (https://github.com/CSSEGISandData/COVID-19).
```{r}
covid <- read_sf(here("data", "raw", "public", "covidcase080120.gpkg"))

# select and rename the fips code, population, cases, and x,y coordinates
covid <- select(covid,
  fips = FIPS,
  pop = POP_ESTIMA,
  cases = Confirmed,
  x = X, y = Y
)

covid_table <- covid %>%
  mutate(covid_rate = round(covid$cases / covid$pop * 100000, 2)) %>%
  st_drop_geometry()
```

Join COVID and ACS

```{r}
# Join COVID incidence rate data to acs data
acs_covid <- acs_derived %>%
  left_join(covid_table, by = "fips")

# move covid_rate column prior to disability percentages
acs_covid <- acs_covid %>%
  select(fips, statefp, county, county_st, covid_rate, everything())

rm(acs, acs_derived, covid)
```

missing data
```{r}
# county with missing data
filter(acs_covid, is.na(bpov_pct)) %>% st_drop_geometry() %>% kable()

# replace NA with 0
acs_covid[is.na(acs_covid$bpov_pct), ]$bpov_pct <- 0
acs_covid[is.na(acs_covid$apov_pct), ]$apov_pct <- 0
```

<!-- COVID incidence Rate Map -->
```{r}
# tm_covid_rates <- tm_shape(acs_covid) +
#   tm_polygons("covid_rate",
#     title = "COVID-19 Cases per 100,000 people\n(22 January 2020 to 1 August 2020)",
#     style = "quantile",
#     border.alpha = .2,
#     lwd = 0.2,
#     palette = "Oranges",
#   ) +
#   tm_shape(state) +
#     tm_borders("grey", lwd = .5) +
#   tm_layout(
#     legend.position = c("left", "bottom"),
#     legend.title.size = 0.8,
#     legend.text.size = 0.5
#   )
# 
# tm_covid_rates
```

<!-- Updated  -->
COVID Incidence Rate TMAP 
```{r}
# Set tmap mode explicitly if needed (e.g., for interactive maps)
# tmap_mode("plot")  # or "view"

tm_covid_rates <- 
  tm_shape(acs_covid) +
    tm_polygons(
      col = "covid_rate",
      title = "COVID-19 Cases per 100,000 people\n(22 Jan 2020 to 1 Aug 2020)",
      style = "quantile",
      border.alpha = 0.2,
      lwd = 0.2,
      palette = "Oranges"
    ) +
  tm_shape(state) +
    tm_borders(
      col = "grey",
      lwd = 0.5
    ) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_covid_rates
```



Disability Map
```{r map-disability-rates, message = FALSE}
# tm_disability_rates <- tm_shape(acs_covid) +
#   tm_polygons("dis_pct",
#     title = "Percent of People with Disability\n(ACS 2014-2018)",
#     style = "quantile",
#     col_alpha = .2,
#     lwd = 0.2,
#     palette = "Oranges"
#   ) +
#   tm_shape(state) +
#   tm_borders("grey", lwd = .5) +
#   tm_layout(
#     legend.position = c("left", "bottom"),
#     legend.title.size = 0.8,
#     legend.text.size = 0.5
#   )
# 
# tm_disability_rates

library(tmap)

# Set tmap mode explicitly if needed
# tmap_mode("plot")  # or "view"

tm_disability_rates <- 
  tm_shape(acs_covid) +
    tm_polygons(
      col = "dis_pct",
      title = "Percent of People with Disability\n(ACS 2014–2018)",
      style = "quantile",
      alpha = 1,
      lwd = 0.2,
      palette = "Oranges"
    ) +
  tm_shape(state) +
    tm_borders(
      col = "grey",
      lwd = 0.2
    ) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_disability_rates


```
```{r compare-descriptive-stats}
# load original table 1 results
table1 <- read.csv(here("data", "raw", "public", "table1.csv"))

# subtract original results from reproduced results
(select(acs_covid_stats, min, max, mean, SD) -
  select(table1, min, max, mean, SD)) %>%
  kable(caption = "Descriptive Statistics Comparison",
        align = "c") %>%
  column_spec(2:5, width = "4em") %>%
  kable_styling(full_width = FALSE)

rm(acs_covid_stats)
```

## Summary Stats
```{r}
acs_covid_stats <- acs_covid %>%
  st_drop_geometry() %>%
  select(covid_rate, contains("pct")) %>%
  stat.desc(norm = TRUE) %>%
  round(2) %>%
  t() %>%
  as.data.frame() %>%
  select(min, max, mean, SD = std.dev, ShapiroWilk = normtest.W, p = normtest.p)

acs_covid_stats %>%
  kable(caption = "Reproduced Descriptive Statistics",
        align = "c") %>%
  column_spec(2:6, width_min = "5em") %>%
  column_spec(7, width_min = "2em") %>%
  kable_styling(full_width = FALSE)
```

## Pearsons
```{r pearsons-correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

pearsons_r <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  select(r = covid_rate) %>%
  mutate(
    t = abs(r) / sqrt((1 - r^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  filter(variable != "covid_rate")

pearsons_r %>%
  kable(caption = "Reproduced Pearson's R",
        align = "c") %>%
  column_spec(2:4, width = "4em") %>%
  kable_styling(full_width = FALSE)
```

Comparison of the reproduced Pearson's *r* correlation coefficients to the original study's Pearson's *r* correlation coefficients.
Stars indicates the significance level with two stars for `p < 0.01` and one star for `p < 0.05`.
Correlation difference `rp_r_diff` is calculated between the reproduction study `rp_r` and original study `or_r` as `rp_r_diff = rp_r - or_r` Direction difference `rp_dir_diff` is calculated as `(rp_r > 0) - (or_r > 0)`, giving `0` if both coefficients have the same direction, `1` if the reproduction is positive and the original is negative, and `-1` if the reproduction is negative but the original is positive.

```{r compare-pearsons-correlation}
# calculate number of significance stars at p < 0.01 and p < 0.05 levels.
pearsons_r <- mutate(pearsons_r, rp_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

# join reproduction coefficients to original study coefficients
correlations <- table1 %>%
  filter(variable != "covid_rate") %>%
  select(variable, or_r = r, or_stars = stars) %>%
  left_join(select(pearsons_r, variable, rp_r = r, rp_stars), by = "variable")

# find difference between coefficient and stars
correlations <- correlations %>%
  bind_cols(rename_with(
    correlations[, 4:5] - correlations[, 2:3],
    ~ paste0(.x, "_diff")
  ))

# find coefficients with different directions
correlations <- correlations %>% mutate(rp_dir_diff = (rp_r > 0) - (or_r > 0))

correlations %>%
  kable(caption = "Compare reproduced and original Pearson's R",
        col.names = c("Variable", "R", "Sig. Level", "R", "Sig. Level", "R", "Sig. Level", "Direction"),
        align = "c") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Original" = 2, "Reproduced" = 2, "Difference" = 3))
```

Reproduction correlation coefficients varied slightly from the original study coefficients by +/- 0.006.
All but one Pearson's correlation coefficient was significant to the same level, and the exception was age 18 to 34.
Counter-intuitively, the correlation coefficient was slightly closer to 0 but the *p* value was also found to be more significant, suggesting a difference in the estimation of *t* and/or *p*, or a typographical error.
All of the coefficients had the same direction.

**Unplanned Deviation for Reproduction**: We should expect identical results for this correlation test, so we loaded the original author's data from `Aug1GEEdata.csv` to re-test the statistic, calculated as `unplanned_r` below.

```{r original-data-pearson-correlation}
# load author-provided original data
original_gee <- read.csv(here("data", "raw", "public", "Aug1GEEdata.csv"))

# calculate correlation coefficients using original data
original_gee %>%
  select(Incidence, PerDisable, starts_with("PD")) %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  rownames_to_column("or_variable") %>%
  filter(or_variable != "Incidence") %>%
  select(or_variable, unplanned_r = Incidence) %>%
  bind_cols(correlations[, 1:2]) %>%
  mutate(unplanned_r = round(unplanned_r, 3), diff = unplanned_r - or_r) %>%
  select(variable, unplanned_r, or_r, diff) %>%
  kable(caption = "Recalculation of Pearson's R with original data",
        align = "c",
        ) %>%
  kable_styling(full_width = FALSE)
```

The author's original data produced coefficients identical to the original publication!
Is it possible that the data values are correct but have been reassigned / transposed to different counties?

*Unplanned Deviation for Reproduction*: Considering the precise bitwise reproduction of descriptive statistics and of correlation statistics from author-provided data, we decided to recalculate the COVID-19 incidence rate with author-provided case and population data for comparison to the author-provided incidence rate.

```{r compare-incidence-rate}
# recalculate Incidence Rate
original_gee <- original_gee %>%
  mutate(recalc_Incidence = round(Cases / Total_POP * 100000, 2))

# compare recalculation to author-provided original data and print any counties
# with inconsistent results
original_gee %>%
  filter(recalc_Incidence != Incidence) %>%
  select(FIPS = COUNTY_FIPS, State = ST_Name, County = Countyname, Population = Total_POP, Cases, OR_Incidence = Incidence, RPr_Incidence = recalc_Incidence) %>%
  mutate(Difference = RPr_Incidence - OR_Incidence) %>%
  kable(caption = "Counties with inconsistent COVID-19 incidence rate") %>%
  kable_styling(latex_options = "scale_down")
```

We found that 13 counties had incorrect COVID-19 incidence scores, and the scores seem to be transposed from other counties, such that the overall descriptive statistics were accurate but the correlation coefficients were inaccurate.
This finding implies that subsequent analyses using the COVID-19 Incidence rate will be slightly different and more accurate in this reproduction study than in the original study.

**Unplanned deviation for reproduction:** Original author's Incidence data joined into our reproduction data frame so that we can later test for sensitivity to this error.
Then report any counties for which the reproduced COVID incidence rate differs from the original author's COVID incidence rate.

```{r join-incidence-rate}
original_incidence <- original_gee %>%
  select(COUNTY_FIPS, or_incidence = Incidence) %>%
  mutate(fips =
           ifelse(COUNTY_FIPS >= 10000,
                  as.character(COUNTY_FIPS),
                  paste0("0", COUNTY_FIPS)
                  )
         )
  # calculates a text version of FIPS code for joining, while adding back
  # the leading '0' if the code was less than 10000

acs_covid <- acs_covid %>%
  left_join(original_incidence, by = "fips")

rm(original_incidence)

acs_covid %>%
  st_drop_geometry %>%
  filter(covid_rate != or_incidence) %>%
  arrange(fips) %>%
  select(county_st, covid_rate, or_incidence) %>%
  kable(caption = "Original incidence rate joined to reproduction data") %>% kable_styling()
```

The join highlights the same 13 counties with inconsistent incidence rates.
This also confirms that our reproduced dependent variable is identical to the original dependent variable with the exception of these three counties.

## Bivariate nonparametric correlation analysis

**Unplanned Deviation for Reproduction**: The dependent and independent variables in this study do not have normal distributions, as shown in the Shapiro-Wilk test results above.
Therefore, we deviate from the original study to use the Spearman's Rho non-parametric correlation test.

```{r spearmans correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

spearmans_rho <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "spearman", use = "everything") %>%
  as.data.frame() %>%
  select(rho = covid_rate) %>%
  mutate(
    t = abs(rho) / sqrt((1 - rho^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  filter(variable != "covid_rate")
```

CSpearman's *rho* correlation coefficients comparee to the reproduced Pearson's *r* correlation coefficients.
Differences are calculated as *Spearman's Rho* - *Pearson's R*.

```{r compare-spearmans-correlation}
# calculate number of significance stars at p<0.01 and P<0.05 levels.
spearmans_rho <- mutate(spearmans_rho, rp_rho_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

correlations <- correlations[, 1:8] %>%
  left_join(select(spearmans_rho, variable, rp_rho = rho, rp_rho_stars), by = "variable")

corrdiff <- select(correlations, starts_with("rp_rho")) -
  select(correlations, rp_r, rp_stars)

correlations <- correlations %>% bind_cols(rename_with(corrdiff, ~ paste0(.x, "_diff")))
rm(corrdiff)

correlations <- correlations %>% mutate(rp_rho_dir_diff = (rp_rho > 0) - (rp_r > 0))

correlations %>%
  select(variable, rp_r, rp_stars, starts_with("rp_rho")) %>%
  kable(col.names = c("Variable", "R", "Stars", "Rho", "Stars", "Rho - R", "Stars", "Direction"),
        align = "c") %>%
  #column_spec(2:6, width_min = "5em") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Pearson's" = 2, "Spearman's" = 2, "Difference" = 3))
```

Three variables change significance levels, with *Native American* and *Other* races gaining significance and *age 18-34* losing significance.
Two correlations change direction, with both *Native American* race (illustrated in scatterplot below) and *Female* households switching from positive correlations to negative correlations.
Instabilities between the parametric and non-parametic correlations arise from variables with very skewed distributions and/or weak correlations at the county level.
Some difference may also be attributable to the 13 counties with data errors in the COVID-19 Incidence Rate.
In such distributions, outlier observations have more weight in the parametric Person's R test than in the non-parametric Spearman's Rho test.

```{r plot-bivariate, fig.width=4, fig.height=4}
plot(acs_covid$native_pct,
  acs_covid$covid_rate,
  xlab = "Percent Native American",
  ylab = "COVID-19 Incidence",
  pch = 16,
  col = rgb(0, 0, 0, 0.05),
  cex.lab = 0.8,
  cex.axis = 0.5,
)
lines(abline(lm(acs_covid$covid_rate ~ acs_covid$native_pct)))

rm(spearmans_rho, pearsons_r, correlations, table1, df)
```

## Kulldorff spatial scan statistic

Although this study did not involve major geographic transformations, it employed specific geographic grouping criteria for the generalized estimating equation (GEE) models, combining state boundaries with COVID-19 risk levels identified using the Kulldorff spatial scan statistic. This statistic, implemented in the SaTScan software, detects spatial clusters of high COVID-19 incidence using spherical great-circle distance calculations based on county centroid coordinates. The geographic coordinates (`X` and `Y` attributes) used for these calculations were sourced from the ACS dataset.

The Kulldorff scan statistic relies on Monte Carlo simulations to determine the statistical significance of clusters, leading to potentially varying results across runs. While the original manuscript specifies use of a Poisson model in SaTScan, other model parameters appear to follow the software's defaults. These include discrete, spatial-only modeling (excluding temporal analysis), a maximum cluster size of 50% of the population at risk, GINI-optimized cluster selection, and non-overlapping secondary clusters. The "P-value Cutoff" setting did not appear in version 9.6, implying that only the default setting was available at the time of analysis.


SaTScan software can also output two versions of geographic data:

-   The `col` cluster polygon shapefile contains a circle for each cluster, where each polygon is a circle defined by the cluster center and radius. The attributes include a variable `REL_RISK` for cluster relative risk
-   The `gis` location point shapefile contains one point for each county in a cluster. The attributes include variables `LOC_RR` for local relative risk and `CLU_RR` for cluster relative risk

The SaTScan software implementation of the Kulldorff spatial scan statistic calculates two relative risk scores for locations:

-   Cluster relative risk is the incidence rate of the population within the cluster divided by the incidence rate of the population outside of the cluster. This is calculated as `REL_RISK` in the `col` cluster polygon shapefile and as `CLU_RR` in the `gis` location point shapefile.
-   Local relative risk is the incidence rate of population within a location divided by the incidence rate of the population outside of the location. This is calculated as `LOC_RR` in the `gis` location shapefile, and is not calculated in the `col` cluster polygon shapefile.

For the purposes of interpreting the spatial scan statistic, a *location* is a *county centroid* while a *cluster* is a *collection of counties* with high incidence rates, defined in the shape of a circle with a *center* location (a county centroid) and a *radius*.

The original study is not clear about using the cluster geographic data *vs* the location geographic data or the cluster relative risk *vs* local relative risk.
However, The author-provided `SatScan_results.txt` results file indicates a geographic cluster file but no location file, and the author-provided `Aug1GEEdata.csv` data table contains a `REL_RISK` field but no `CLU_RR` field or `LOC_RR` field.
This suggests that in the original study, the `col` polygon cluster shapefile and *cluster* relative risk were used to represent COVID-19 risk and define GEE clusters.

The spatial scan statistic is based on case counts and total population, and is therefore unaffected by errors in the COVID Incidence rate.

**Planned deviation for reproduction**: We opted to use the SpatialEpi package in R, selecting open source software with R integration over SatSCan software, which is free but not open.
The Kulldorff spatial scan statistic model in SpatialEpi also supports a discrete Poisson spatial model, and uses the GINI coefficient to select secondary clusters with no geographical overlap that maximize the difference between locations inside of clusters and locations outside of clusters.
We expected that this set of software options could reproduce identical results compared to SaTScan.

First, calculate the Kulldorff spatial scan statistic using SpatialEpi.
Optionally, skip this code block due to long run times of more than 10 minutes.

```{r SpatialEpi-Kulldorff, eval = FALSE, fig.width=4, fig.height=4}
start_time <- Sys.time()
covid_geo <- covid_table %>%
  select(x, y) %>%
  latlong2grid()
# latlong2grid creates approximate equidistant cylindrical grid
# could probably reproject to epsg 5070 and create table with x and y

# calculate expected cases with one strata
expected.cases <- expected(covid_table$pop, covid_table$cases, 1)

# Kulldorff spatial scan statistic
covid_kulldorff <- kulldorff(
  geo = covid_geo,
  cases = covid_table$cases,
  population = covid_table$pop,
  expected.cases = expected.cases,
  pop.upper.bound = 0.5,
  n.simulations = 999,
  alpha.level = 0.05,
  plot = TRUE
)

print(
  paste(
    "Run time:",
    round(difftime(Sys.time(), start_time, units = "mins"), 2),
    "minutes"
  ),
  quote = FALSE
)
rm(covid_geo, expected.cases, start_time)

# save results in a file appended with the current date
saveRDS(covid_kulldorff,
  file = here("data", "derived", "public", paste0("covid_kulldorff_", Sys.Date(), ".RDS"))
)
```

Load pre-calculated Kulldorff spatial scan results.

```{r load-Kulldorff}
# load pre-calculated Kulldorff results
# alternatively, modify the file name with an appended date to load a more current set of results
covid_kulldorff <- readRDS(
  here("data", "raw", "public", "covid_kulldorff.RDS")
)
```

Report Kulldorff spatial scan results.

```{r report-Kulldorff}
print("Most likely cluster:", quote = FALSE)
covid_kulldorff$most.likely.cluster
print(
  paste0(
    "Number of Secondary clusters: ",
    length(covid_kulldorff$secondary.clusters)
  ),
  quote = FALSE
)
```



Clusters include the county at the center of a cluster and all of the other counties within the cluster radius.
FIPS code of the county at the center of each cluster as the unique cluster ID is used.

```{r assign-cluster-IDs, message = FALSE}
# list of primary cluster locations (counties)
cluster_locations <- covid_kulldorff$most.likely.cluster$location.IDs.included

# create data frame of clusters and
# calculate the clusterID as the first (center) county FIPS code
clusters <- covid_table[cluster_locations, "fips"] %>%
  mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
         likelihood = covid_kulldorff$most.likely.cluster$log.likelihood.ratio)

# Get a list of secondary clusters
secondary <- covid_kulldorff$secondary.clusters

# similarly add counties in each secondary cluster to the list of clusters
for (i in secondary) {
  cluster_locations <- i$location.IDs.included
  new_clusters <- covid_table[cluster_locations, "fips"] %>%
    mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
           likelihood = i$log.likelihood.ratio)
  clusters <- clusters %>% rbind(new_clusters)
}

rm(cluster_locations, secondary, i, new_clusters)
```

### Map Kulldorff clusters

**Unplanned deviation for reproduction**: The original study does not include visualizations of the spatial structure and distribution of COVID-19 clusters.

Join the Kulldorff spatial scan cluster IDs to the acs_covid simple features.

Calculate a new field `isCluster` to identify counties in COVID-19 clusters.
Distinguish between counties defining the center of a cluster from counties constituting other parts of a cluster by comparing the cluster ID (equivalent to the center county's fips code) to the county fips code.

```{r join-clusterID-to-acs_covid}
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "or_incidence")] %>%
  left_join(clusters, by = "fips") %>%
  mutate(isCluster = case_when(
    clusterID == fips ~ "center of cluster",
    !is.na(clusterID) ~ "other part of cluster",
    .default = NA
  ))
```

**Planned deviation for reproduction**: Map the `SpatialEpi` cluster results.

```{r map-clusters}
tm_spatialepi_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "isCluster",
          palette = "-Oranges",
          popup.vars = c("fips", "clusterID"),
          colorNA = NULL,
          title = "SpatialEpi Kulldorff COVID-19 Clusters",
          border.col = "white",
          lwd = 0.2,
          border.alpha = 0.2) +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

# tm_spatialepi_clusters
```

**Unplanned deviation for reproduction**: Calculate local and cluster relative risk

```{r relative-risk}
total_pop <- sum(acs_covid$pop)
total_cases <- sum(acs_covid$cases)

acs_covid <- acs_covid %>%
  group_by(clusterID) %>%
  mutate(
    rr_cluster = ifelse(is.na(clusterID), NA,
      (sum(cases) / sum(pop)) / ((total_cases - sum(cases)) / (total_pop - sum(pop)))
    )
  ) %>%
  ungroup() %>%
  mutate(
    rr_loc = (cases / pop) / ((total_cases - cases) / (total_pop - pop))
  )

rm(total_pop, total_cases)
```

Classify relative risk on a scale from 1 to 6 (workflow step 8).
Risk is classified according to this table:

| Relative Risk Values | Relative Risk Class |
|:--------------------:|:-------------------:|
|  Outside of cluster  |          1          |
|       RR \< 1        |          1          |
|    1 \<= RR \< 2     |          2          |
|    2 \<= RR \< 3     |          3          |
|    3 \<= RR \< 4     |          4          |
|    4 \<= RR \< 5     |          5          |
|    5 \<= RR \< 6     |          6          |

Counties falling outside of any cluster are assigned a score of 1.

```{r classify-relative-risk}
# class breaks
breaks <- c(-Inf, 1, 2, 3, 4, 5, Inf)

acs_covid <- acs_covid %>%
  mutate(
    cluster_class = ifelse(is.na(clusterID), 1, cut(rr_cluster, breaks, labels = FALSE)),
    loc_class = cut(rr_loc, breaks, labels = FALSE)
  )
```

### Map relative risk scores

**Unplanned deviation for reproduction**: 

Spatial distribution of local relative risk score classifications.

```{r map local relative risk score}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(loc_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$loc_class,
                           " (",
                           class_freq$n,
                           class_freq$qual,
                           ")")

# Map Local Relative Risk scores
# tm_spatialepi_local_risk_class <- tm_shape(acs_covid) +
#   tm_polygons("loc_class",
#     title = "Local Relative Risk Class",
#     border.col = "white",
#     border.alpha = .2,
#     lwd = 0.2,
#     palette = "Oranges",
#     style = "cat",
#     labels = class_freq$label
#   ) +
#   tm_shape(state) +
#   tm_borders("grey", lwd = .5) +
#   tm_layout(
#     legend.position = c("left", "bottom"),
#     legend.title.size = 0.8,
#     legend.text.size = 0.5
#   )

library(tmap)

# Set tmap mode explicitly if needed
# tmap_mode("plot")  # or "view"

tm_spatialepi_local_risk_class <- 
  tm_shape(acs_covid) +
    tm_polygons(
      col = "loc_class",
      title = "Local Relative Risk Class",
      border.col = "white",
      border.alpha = 0.2,
      lwd = 0.2,
      palette = "Oranges",
      style = "cat",
      labels = class_freq$label
    ) +
  tm_shape(state) +
    tm_borders(
      col = "grey",
      lwd = 0.5
    ) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_local_risk_class


rm(class_freq)

tm_spatialepi_local_risk_class
```

Map of cluster relative risk scores for comparison.
- Counties outside of clusters are assigned the lowest risk class of `1`.

```{r map-cluster-relative-risk-classes}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(cluster_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$cluster_class,
                           " (",
                           class_freq$n,
                           class_freq$qual,
                           ")")

# map cluster relative risk scores
# tm_spatialepi_cluster_risk_class <- tm_shape(acs_covid) +
#   tm_polygons("cluster_class",
#     title = "Cluster Relative Risk Class",
#     border.col = "white",
#     border.alpha = .2,
#     lwd = 0.2,
#     palette = "Oranges",
#     style = "cat",
#     labels = class_freq$label
#   ) +
#   tm_shape(state) +
#   tm_borders("grey", lwd = .5) +
#   tm_layout(
#     legend.position = c("left", "bottom"),
#     legend.title.size = 0.8,
#     legend.text.size = 0.5
#   )


library(tmap)

# Set tmap mode explicitly if needed
# tmap_mode("plot")  # or "view"

tm_spatialepi_cluster_risk_class <- 
  tm_shape(acs_covid) +
    tm_polygons(
      col = "cluster_class",
      title = "Cluster Relative Risk Class",
      border.col = "white",
      border.alpha = 0.2,
      lwd = 0.2,
      palette = "Oranges",
      style = "cat",
      labels = class_freq$label
    ) +
  tm_shape(state) +
    tm_borders(
      col = "grey",
      lwd = 0.5
    ) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_cluster_risk_class


rm(class_freq)

tm_spatialepi_cluster_risk_class
```

The larger clusters in the southeast have an averaging impact on the cluster risk scores when compared to smaller clusters in the region.

This effect is more pronounced for clusters with low compactness (e.g. the Southeast cluster stretched over the "black belt" region from Louisiana and Arkansas to Georgia) than clusters with higher compactness (e.g. New York City) because the circular shape of clusters includes more low-risk counties.

### Compare clusters

The original study did not directly report any results from the Kulldorff spatial scan statistic.
However, the Kulldorff cluster relative risk scores were combined with states to create clusters for GEE models, hereafter called "GEE clusters".
The original study reported `102` unique GEE clusters having a range of `1` to `245` counties in each cluster.

In order to compare results, we first create cluster IDs as combinations of the state ID and COVID relative risk class.
The first clustering ID (State) and second clustering score (COVID relative risk class) were combined to form IDs for each unique combination of state and relative risk class.
Then, we find the number of unique clusters and frequency counties per cluster in our reproduction study for comparison to the original study.

```{r make-gee-clusters}
# calculate clusters
acs_covid <- acs_covid %>% mutate(
  rp_clusID = as.integer(statefp) * 10 + cluster_class
)

# summarize clustering results
cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(rp_clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
rm(cluster_summary)
```

We failed to reproduce the same configuration of GEE clusters as the original study, finding 9 more clusters than the original study and a much smaller maximum cluster of 159 counties compared to 245 counties.

### Reproduce Kulldorff spatial scan statistic in SaTScan

**Unplanned deviation for reproduction**: Upon failing to reproduce an identical number of GEE clusters using SpatialEpi in R, we reproduced the procedure in the free but not open SaTScan software, using the current software version 10.1.
The input data files (`case`, `Coordinates.geo`, and `Population.pop`), and output data files (`sat_scan_rpr.txt`, `sat_scan_rpr.col.shp`, and `sat_scan_rpr.gis.shp`) are found in the `data/derived/public/satscan` directory.
The `sat_scan_rpr.txt` file reports the model parameters used in addition to results.


```{r load-satscan-col}
# load author-provided data
author_col <- read.dbf(here("data", "raw", "public", "SatScan_output.dbf")) %>%
  select(LOC_ID, or_rel_risk = REL_RISK)
here()

# load SaTScan reproduced data
# Download satscan data
satscan_rpr_col <- read_sf(here("data", "raw", "public", "sat_scan_rpr.col.shp"))

# how many observations?
cat(
  nrow(satscan_rpr_col),
  " reproduced relative risk observations\n",
  nrow(author_col),
  " author-provided relative risk observations\n",
  sep = ""
)

# join and compare how many observations are identical?
cat(
  satscan_rpr_col %>%
  full_join(author_col, by = "LOC_ID") %>%
  filter(REL_RISK == or_rel_risk & REL_RISK > 0) %>%
  nrow(),
  "reproduced relative risk values match the original author's relative risk values"
  )

rm(author_col)
```

Our SaTScan results exactly reproduced the author-provided SaTScan results data.

#### Map SaTScan spatial clusters

Join the SaTScan results to `acs_covid` for mapping and analysis.

```{r join-satscan-to-acs-covid}
# check if there are any duplicated counties
cat("Joining",
    length(satscan_rpr_col$LOC_ID),
    "records with",
    length(unique(satscan_rpr_col$LOC_ID)),
    "unique LOC_ID county values")

# select important non-geographic columns
satscan_rpr_col_t <- satscan_rpr_col %>%
  st_drop_geometry() %>%
  select(fips = LOC_ID, GINI_CLUST, REL_RISK)

# join
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "rp_clusID")] %>%
  left_join(satscan_rpr_col_t, by = "fips")

rm(satscan_rpr_col_t)
```

**Unplanned deviation for reproduction**: Visualize the spatial distribution of the author-provided Kulldorff COVID-19 Clusters.

```{r map--author-clusters}
# count frequencies of each cluster type
clus_counts <- satscan_rpr_col %>%
  st_drop_geometry() %>%
  group_by(GINI_CLUST) %>%
  summarize(n = n())

# create labels including frequencies in brackets
clus_labels <- c(paste0("Hierarchical (", clus_counts[1,2], ")"),
            paste0("GINI Optimized (", clus_counts[2,2], ")"))

# for clusters with only one county, erase the number of counties
satscan_rpr_col[which(satscan_rpr_col$NUMBER_LOC < 3), ]$NUMBER_LOC <- NA

gini_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'T')
hier_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'F')

tm_author_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "GINI_CLUST",
              labels = clus_labels,
              border.col = "white",
              lwd = 0.5,
              palette = c("tomato", "thistle3"),
              popup.vars = c("fips", "clusterID"),
              colorNA = NULL,
              title = "SaTScan Kulldorff COVID-19 Clusters\nCluster Centers") +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_shape(gini_circle) +
    tm_borders(col = "thistle4") +
    tm_text("NUMBER_LOC", size = 0.5) +
  tm_shape(hier_circle) +
    tm_borders(col = "tomato") +
    tm_text("NUMBER_LOC", size = 0.5, ymod = 0.4) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  ) +
  tm_add_legend('symbol',
              	col = NA,
              	border.col = c("tomato", "thistle4"),
              	size = 0.7,
              	labels = clus_labels,
              	title="Cluster Extents")

tm_author_clusters

rm(gini_circle, hier_circle, clus_counts, clus_labels)
```

In the map above, clusters containing only one county have no visible circle.
Clusters containing two counties are encircled, but have no label.
Clusters containing three or more counties are encircled and labelled with the number of counties.

Note that this version of data only includes the 96 counties defining cluster centers, visualized with fill colors above.
The data excludes all of the non-center counties in clusters with more than one county.
The extent of these larger clusters is visualized by unfilled circles defined by cluster radii.

Additionally, the SaTScan software confusingly merges two sets of clusters in the results when the user uses the (default) option for GINI-optimized clusters.
One set of results is a hierarchical non-overlapping set of clusters.
These clusters are noted with `GINI_CLUST = F` in the results.
The second set of results is a set of hierarchical non-overlapping clusters designed to maximize the GINI coefficient of inequality between counties within clusters and counties outside of clusters.
These clusters are noted with `GINI_CLUST = T` in the results.

Merged together as they are, the two sets of secondary clusters overlap one another geographically, causing ambiguity in terms of which cluster-based relative risk score should be used at each location.

**Unplanned deviation for reproduction**: Can we also use these reproduced SaTScan results to exactly reproduce the author-reported frequency of original GEE classes and maximum counties per class?
If the results match, it will confirm that the problems identified above have propagated through the original study analysis.

```{r reproduce-gee-clusters}
acs_covid <- acs_covid %>%
  mutate(
    ss_cluster_class = ifelse(is.na(REL_RISK), 1, cut(REL_RISK, breaks, labels = FALSE)),
    ss_clusID = as.integer(statefp) * 10 + ss_cluster_class
  )

cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(ss_clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
```

Using SaTScan Kulldorff clusters, we have exactly reproduced the author-reported frequency of original GEE classes and maximum counties per class.
We have confirmed that the original study used the *cluster relative risk* of the *center county* of each cluster, including both the *hierarchical* and *GINI-optimized* sets of clusters.

#### Compare SaTScan clusters to SpatialEpi clusters

**Unplanned Deviation for Reanalysis:** At this point it is clear that the best decision will be to shift from a *reproduction* study to a *reanalysis* study, intentionally altering methodological decisions to achieve a more valid outcome.
We prefer to include *all counties* contained in each cluster, and to use only *one set of non-overlapping clusters*, as produced by the `SpatialEpi` algorithm.

Given the shifting goal, how sensitive is this study to the choice of computational environment for the Kulldorff scan statistics?
To answer this question, we must load the local SaTSCan results inclusive of all counties within clusters, filter the results to focus on the standard hierarchical set of clusters, and compare the spatial distributions of the SaTScan and SpatialEpi results.

```{r join-satscan-clusters-all-counties, message = F}
# load local SaTScan reproduced data
satscan_rpr_gis_t <- read_sf(
  here("data", "derived", "public", "satscan", "sat_scan_rpr.gis.shp")
) %>%
  st_drop_geometry() %>%
  select(fips = LOC_ID, CLU_RR, GINI_CLUST)

# check if there are any duplicated counties
cat("SaTScan combined GIS output has",
    length(satscan_rpr_gis_t$fips),
    "records with",
    length(unique(satscan_rpr_gis_t$fips)),
    "unique county values\n")

satscan_rpr_gini <- satscan_rpr_gis_t %>% filter(GINI_CLUST == "T") %>% select(fips, gini_rr = CLU_RR)
satscan_rpr_hier <- satscan_rpr_gis_t %>% filter(GINI_CLUST == "F") %>% select(fips, hier_rr = CLU_RR)

# check if there are any duplicated counties
cat("SaTScan Hierarchical clusters include",
    length(satscan_rpr_hier$fips),
    "records with",
    length(unique(satscan_rpr_hier$fips)),
    "unique county values\n")

cat("SaTScan GINI-optimized clusters include",
    length(satscan_rpr_gini$fips),
    "records with",
    length(unique(satscan_rpr_gini$fips)),
    "unique county values")

acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "ss_clusID")] %>%
  left_join(satscan_rpr_gini, by = "fips") %>%
  left_join(satscan_rpr_hier, by = "fips")

rm(satscan_rpr_gis_t, satscan_rpr_gini, satscan_rpr_hier)
```

It was necessary to divide the Hierarchical clusters from the GINI clusters to avoid duplicates and geographic overlap.

Compare the SaTScan Hierarchical clusters to the SpatialEpi clusters.

```{r hierarchical-cluster-comparison-map, message = F}
hier_clusters <- acs_covid %>%
  mutate(xcluster = case_when(
    !is.na(hier_rr) & is.na(isCluster) ~ "SaTScan Hierarchical only",
    !is.na(hier_rr) & !is.na(isCluster) ~ "Both SaTScan and SpatialEpi",
    is.na(hier_rr) & !is.na(isCluster) ~ "SpatialEpi only",
    .default = NA
  )) %>%
  filter(!is.na(xcluster)) %>%
  group_by(xcluster) %>%
  mutate(xn = n()) %>%
  ungroup() %>%
  mutate(xcluster = paste0(xcluster, " (", xn, " counties)"))

tm_spatialepi_hier <-
  tm_shape(state) +
  tm_fill("gray98") +
  tm_shape(hier_clusters) +
  tm_polygons(
    col = "xcluster",
    palette = c("wheat", "tomato", "thistle3"),
    colorNA = NULL,
    title = "SaTScan Hierarchical and SpatialEpi Clusters",
    border.col = "white",
    lwd = 0.2,
    border.alpha = 0.3
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_hier

rm(hier_clusters)
```

The two methods only agree on the definition of the largest clusters in distant regions.
Thereafter, SpatialEpi detects many secondary clusters in the vicinity of the largest ones, while SaTScan detects seven isolated and low-probability counties.

Compare the SaTScan GINI Optimized clusters to the SpatialEpi clusters.

```{r gini-cluster-comparison-map, message = F}
gini_clusters <- acs_covid %>%
  mutate(xcluster = case_when(
    !is.na(gini_rr) & is.na(isCluster) ~ "SaTScan GINI optimized only",
    !is.na(gini_rr) & !is.na(isCluster) ~ "Both SaTScan and SpatialEpi",
    is.na(gini_rr) & !is.na(isCluster) ~ "SpatialEpi only",
    .default = NA
  )) %>%
  filter(!is.na(xcluster)) %>%
  group_by(xcluster) %>%
  mutate(xn = n()) %>%
  ungroup() %>%
  mutate(xcluster = paste0(xcluster, " (", xn, " counties)"))

tm_spatialepi_gini <-
  tm_shape(state) +
  tm_fill("gray98") +
  tm_shape(gini_clusters) +
  tm_polygons(
    col = "xcluster",
    palette = c("wheat", "tomato", "thistle3"),
    colorNA = NULL,
    title = "SaTScan GINI Optimized and SpatialEpi Clusters",
    border.col = "white",
    lwd = 0.2,
    border.alpha = 0.3
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_gini

rm(gini_clusters)
```

There is more agreement overall between SpatialEpi and SaTScan GINI Optimized clusters.
The two algorithms agree the most for smaller and less significant clusters above the 95% confidence threshold.
Because the SaTScan clusters are more limited in size, SaTScan detects several smaller clusters with gaps in place of the largest SpatialEpi clusters.

Keeping in mind that the final analysis uses a classification of cluster relative risk for GEE models, are there important differences between the two results with regard to classification of risk?
We can check by calculating cluster relative risk classes based on the SaTScan GINI clusters, and cross-tabulating with the SpatialEpi risk classes.

```{r compare-spatialepi-satscan}
acs_covid <- acs_covid %>%
  mutate(
    gini_class = ifelse(is.na(gini_rr), 1, cut(gini_rr, breaks, labels = FALSE)),
    gini_clusID = as.integer(statefp) * 10 + gini_class
  )

table(acs_covid$cluster_class, acs_covid$gini_class) %>%
  kable(row.names = TRUE, caption = "COVID-19 Risk Class by County", align = "c") %>%
  column_spec(2:7, width = "3em") %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(2, bold = TRUE) %>%
  add_header_above(c("SpatialEpi" = 1, "SatScan" = 6)) %>%
  kable_styling(full_width = FALSE, row_label_position = "c")
```

Indeed, SpatialEpi has identified more than 300 counties with above normal risk that were not identified by SaTScan.
Meanwhile, SaTScan identified 78 counties with above normal risk that were not identified by SpatialEpi.

The maps and crosstabulation above indicate that there are important differences between the SaTScan and SpatialEpi computational environments for calculating secondary clusters.

We summarize our understanding of the computational differences for default settings below, based on close examination of our software outputs, technical documentation for SaTScan, and the documentation and code repository for SpatialEpi.

|                          |      SaTScan Hierarchical      |            SaTScan GINI            |                  SpatialEpi                  |
|:----------------:|:----------------:|:----------------:|:----------------:|
|     possible shapes      |  circle (default) or ellipse   |    circle (default) or ellipse     |                    circle                    |
| possible cluster centers | locations with rates \> normal |   locations with rates \> normal   |                all locations                 |
|   maximum cluster size   |          50% of cases          | varies, not exceeding 50% of cases |              50% of population               |
|  maximum *p* of cluster  |              1.00              |                1.00                |                     0.05                     |
|         distance         |     spherical great circle     |       spherical great circle       | spherical equidistant cylindrical projection |

To further interrogate the differences in sets of secondary clusters, we must understand that theoretically each location (county), may be the center of many different circular clusters defined by different radii, starting with a radius of 0 and the one county at the center, and expanding until the maximum cluster size is reached.

**SaTScan Hierarchical Clusters**

-   Select locations (counties) with above-normal COVID incidence rates
-   For each location, find log-likelihood of all possible cluster sizes (from minimum of 2 cases to maximum of 50% of cases) with *p* \< 1
-   For each location, select the cluster with the maximum log-likelihood, resulting in one possible cluster for each location with above-normal COVID incidence rates
-   Sort the remaining clusters by log-likelihood from greatest to least
-   Select the most likely cluster
-   Select secondary clusters by iterating over the remaining clusters, adding new clusters to the set of secondary clusters if they do not geographically overlap any of the clusters already identified as most likely or secondary (pg 68).

**SaTScan GINI-Optimized Clusters**

-   Follow the same procedure as SaTScan Hierarchical clusters, but iterate the procedure with different maximum cluster sizes. By default the cluster sizes include 1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 45, and 50 percent of cases. With the default setting, the result is 17 different sets of clusters.
-   For each set of clusters, calculate the GINI coefficient of the COVID-19 incidence inside the clusters vs outside the clusters.
-   Select the set of clusters with the highest GINI coefficient (i.e. the most difference between COVID-19 incidence inside the clusters vs outside the clusters).

**SpatialEpi Clusters**

-   For all locations, calculate the log likelihood of all the possible clusters below the maximum cluster size (50% of population)
-   Select the clusters with *p* \< 0.05
-   Sort the remaining clusters by log-likelihood from greatest to least (line 186)
-   Select the most likely cluster
-   Select secondary clusters by iterating over the remaining clusters, adding new clusters to the set of secondary clusters if they do not geographically overlap any of the clusters already identified as most likely or secondary (line 199).

The differences between these three approaches have very significant impacts on the results (see the differences in results in the **two maps** above) and it is impossible to control for all of the differences with the available parameters.
Most fundamentally, SaTScan develops sets of secondary clusters from a universe of just one most likely cluster per location with no default limitation its statistical significance, whereas SpatialEpi may consider multiple possible cluster sizes for each location with a default limitation of maximum 0.05 *p* for each cluster.
These fundamental differences are evident in the spatial distribution of clusters.
For example, New York City is the most likely cluster in all analyses.
For counties near New York, the radius of the most likely cluster is large and geographically overlaps New York City.
Therefore, if only the most significant cluster radius is considered as a possible secondary cluster for counties near New York City, all such clusters are disqualified by their geographical overlap.
This is what happens in the SaTScan Hierarchical Clusters model, for which the next nearest clusters are in Ohio and Virginia.
In the SaTScan GINI-optimized model, the maximum cluster size is apparently smaller, such that the most likely cluster in New York City is also smaller.
This change allows for two other non-overlapping secondary clusters in Rhode Island and New Jersey.
In contrast, the SpatialEpi algorithm still considers a variety of possible cluster sizes for each county, allowing for detection of smaller clusters adjacent to more significant ones.

Of course, the *relative risk* score of each cluster is contingent on the cluster size, so each difference in geographic configuration of clusters also impacts the cluster risk classification of individual locations.
The most stable results are for the most likely clusters in distinct regions (New York City, Southeast U.S., Southern California & Nevada), while the most variability appears for secondary clusters close enough for their most likely radius to overlap the more likely clusters.
The circular shape could be considered a major limitation of Kulldorff cluster detection, for which the SaTScan methodology enhances the limitation by constraining the possibility of nearby clusters while the SpatialEpi methodology can detect smaller adjacent secondary clusters.

The high significance threshold in the default SaTScan analysis allows the inclusion of many small clusters with low likelihoods, adding noise to the results.
This could be controlled by overriding the maximum *p* value parameter.
Combining all of the default parameters, SaTSCan includes small clusters of relatively low-risk counties in the Midwest, but excludes relatively high-risk counties adjacent to the major clusters of New York, the Southeast, and Southern California/Nevada.
This problem does not exist in the SpatialEpi implementation, and the SpatialEpi parameter *alpha level* parameter cannot be practically increased to `1` to match the SatSCan default.
This is because SpatialEpi does not filter counties by those with local relative risk greater than 1---therefore an *alpha value* of `1` results in *all* counties being included as clusters.

In sum, there are three construct validity issues with the original study's COVID-19 high-risk clusters as implemented in SaTScan.

1.  Two sets of overlapping secondary clusters are included in the SaTScan output: hierarchical clusters and clusters optimized by GINI coefficient.
2.  Only the 96 counties at the center of a cluster are considered in the risk classification.
3.  The geographic patterns and cluster relative risk scores of secondary clusters are limited to circles or ellipses and are apparently sensitive to both the geographic shape and situation of high-risk clusters and to subjective decisions in parameters and algorithms.

## Preprocess data for GEE modelling

**Unplanned deviation for reanalysis**: Based on the three observations above, we think that it would be more valid to choose one set of secondary clusters based on a single method rather than combining a set of hierarchical clusters with a set of GINI optimized clusters.
We also think that it would be more valid to include risk levels for all counties within a cluster (i.e. all counties within any of the circles above), rather than only the county at the center of a cluster.
Finally, we think it would be more valid to treat clusters as a single category rather than five tiers of above-normal risk.

To complete the reproduction/reanalysis study, we will therefore calculate and compare multiple versions of the GEE models:

1.  Original study results
2.  Original study data in geepack
3.  SpatialEpi cluster classification in geepack
4.  SpatialEpi binary clusters in geepack

### Unique GEE cluster IDs

First, calculate GEE cluster IDs.

We have already calculated: - `rp_clusID` based on our SpatialEpi clusters - `ss_clusID` based on our SaTScan cluster centers, and shown to be identical to the original author's data - `gini_clusID` based on our SaTScan GINI-optimized clusters

### Filter and standardize data

Second, filter the data for non-zero COVID-19 rates and z-score standardize the independent variables.
This accomplishes step 10 of the workflow diagram.

**Unplanned deviation for reproduction:** We assumed that we should filter for COVID rates \> 0 first and then calculate z-scores, however after comparing data in the next code block, we realized that the original study had *first* calculated z-scores and *then* filtered for COVID rates \> 0.
Therefore, to align with the original study, in the next code block we first calculate z-scores and then filter for COVID rates \> 0.

```{r filter-standardize}
gee_data <- acs_covid %>%
# filter(covid_rate > 0) %>% # moved filtering to after z-score calculation
  mutate(
    z_white_pct = scale(white_pct),
    z_black_pct = scale(black_pct),
    z_native_pct = scale(native_pct),
    z_asian_pct = scale(asian_pct),
    z_other_pct = scale(other_pct),
    z_non_hisp_white_pct = scale(non_hisp_white_pct),
    z_hisp_pct = scale(hisp_pct),
    z_non_hisp_non_white_pct = scale(non_hisp_non_white_pct),
    z_bpov_pct = scale(bpov_pct),
    z_apov_pct = scale(apov_pct),
    z_pct_5_17 = scale(pct_5_17),
    z_pct_18_34 = scale(pct_18_34),
    z_pct_35_64 = scale(pct_35_64),
    z_pct_65_74 = scale(pct_65_74),
    z_pct_75 = scale(pct_75),
    z_male_pct = scale(male_pct),
    z_female_pct = scale(female_pct)
  ) %>%
  filter(covid_rate > 0) # moved filtering from before z-score calculation
```

Compare independent variables for GEE models by subtracting the original values from the reproduced values, and finding the average and standard deviation of difference for each variable.

```{r compare-indp-vars}
# subtract original data matrix (table) from reproduced data matrix (table)
# select, filter, and arrange (sort) data to make identical matrix sizes with
# identical order of observations (counties)
gee_diff <-
  (gee_data %>%
    st_drop_geometry() %>%
    arrange(as.integer(fips)) %>%
    select(starts_with("z_"))  -
  original_gee %>%
    filter(Cases > 0) %>%
    arrange(COUNTY_FIPS) %>%
    select(starts_with("ZPD"))) %>%
  round(digits = 3)

# print results
# this would be better as a table
cat("Summary of difference between reproduction independent variables and original independent variables")
cat("\n")
cat("Mean:\n")
colMeans(gee_diff) %>% round(digits = 3)
cat("\nStandard deviation:\n")
apply(gee_diff, 2, sd) %>% round(digits = 3)
```

When we had filtered for COVID rates \> 0 first and then z-score standardized second, the means of differences ranged from -0.012 to 0.004, and standard deviations of differences ranged from 0.000 to 0.016.

After changing the order to first z-score standardize and then filter for COVID rates \> 0, we observed no mean difference between our reproduced variables and the original variables, and we find no standard deviation \> 0.001 for the difference between reproduction independent variables and original variables.
There are no major differences between the independent variables.

#### Save final derived data

Optionally, you may save the preprocessed data to `data/raw/public/gee_data.gpkg`

```{r save preprocessed COVID cluster data, eval = FALSE}
write_sf(gee_data, here("data", "derived", "public", "gee_data.gpkg"))
# add saving acs_covid data
```

Optionally, you may load the preprocessed data from `data/raw/public/gee_data.gpkg`

```{r load preprocessed COVID cluster data, eval = FALSE}
gee_data <- read_sf(here("data", "derived", "public", "gee_data.gpkg"))
```

## GEE models

The generalized estimating equation (GEE) models were used to test association between intra-categorical rates of disability and COVID-19 incidence rates while accounting for spatial clustering.
A separate hypothesis was formulated for each type of subcategorization of PwDs, numbered H2.1 through H2.5 in Table 4.

As specified by the author, "GEEs extend the generalized linear model to accommodate clustered data, in addition to relaxing several assumptions of traditional regression (i.e., normality)".
Additionally, the author noted that "clusters of observations must be defined based on the assumption that observations within a cluster are correlated while observations from different clusters are independent." All five GEE models were specified with exchangeable correlation matrices, gamma distributions, and logarithmic link function.
These specifications were chosen after testing each alternative and choosing the models with the best quasilikelihood under the independence model criterion (QIC).

This accomplishes the step 11 of the workflow diagram.

Generalized Estimating Equation parameters:

"The **'exchangeable' correlation matrix** was selected for the results reported here, since this specification yielded the best statistical fit based on the QIC (quasi- likelihood under the independence) model criterion." (Chakraborty 2021, Methods paragraph 5)

"The **gamma distribution** with **logarithmic link function** was chosen for all GEEs since this model specification provided the lowest QIC value." (Chakraborty 2021, Methods paragraph 5)

### Original Table 2

Load digitized version of Table 2 from the original publication.

```{r load-table2}
table2 <- read.csv(here("data", "raw", "public", "chakraborty", "table2.csv"))
table2 <- table2 %>%
  arrange(row_i_first) #%>%
  #column_to_rownames("term")

table2[, 3:ncol(table2)] %>%
  kable(caption = "Original Publication Table 2",
        align = "c") %>%
  kable_styling()
```

### GEE Function

Define a function for calculating and summarizing five GEE models

```{r gee-functions}
onegee <- function(gee_data, dep_var, id, term_names) {

  # sort data frame by clustering variable, a requirement of GEE modeling
  gee_data <- gee_data %>% arrange({{ id }})

  # create list of models and their independent variables
  model_names <- c(
    "race",
    "ethnicity",
    "poverty status",
    "age",
    "biological sex"
  )

  ind_vars <- c(
    "z_white_pct + z_black_pct + z_native_pct + z_asian_pct + z_other_pct",
    "z_non_hisp_white_pct + z_hisp_pct + z_non_hisp_non_white_pct",
    "z_bpov_pct + z_apov_pct",
    "z_pct_5_17 + z_pct_18_34 + z_pct_35_64 + z_pct_65_74 + z_pct_75",
    "z_male_pct + z_female_pct"
  )

  gee_models <- data.frame(model_names, ind_vars)
  gee_model <- list()

  # empty data frame for storing model outputs
  coefficients <- data.frame()
  qics <- data.frame(model_names, qic = c(1:5))

  # run each model and save outputs
  for(i in 1:nrow(gee_models)){

    # run model
    gee_model[[i]] <- geeglm(
      formula = as.formula(paste(dep_var, "~", gee_models[i, "ind_vars"])),
      data = gee_data,
      id = {{ id }}, # cluster IDs
      family = Gamma(link = "log"),
      corstr = "exchangeable",
    )

    # tidy and save variable coefficients, margins of error, significance...
    gee_table <- tidy(gee_model[[i]], conf.int = TRUE)
    gee_table[1, 1] <- paste(gee_models[i, 1], "model intercept")
    coefficients <- coefficients %>% rbind(gee_table)

    # QIC: quasi-likelihood under the independence model information criterion
    QIC(gee_model[[i]])
    qics[i, 2] <- QIC(gee_model[[i]])[1]

    gee_model[[i]]$model <- NA
  }

  # calculate significance levels
  coefficients$stars <- as.numeric(
    as.character(
      cut(coefficients$p.value,
        breaks = c(-0.1, 0.01, 0.05, 1),
        labels = c(2, 1, 0)
      )
    )
  )

  # reorder columns to match table2 in publication and round to 3 sig. digits
  coefficients <- coefficients %>%
    select("estimate", "std.error", starts_with("conf"), "stars", "p.value") %>%
    round(digits = 3)

  # add tidy term names
  coefficients <- bind_cols(term = term_names, coefficients)

  # combine coefficient results and QIC results into a list
  return_data <- list(
    "coefficients" = coefficients,
    "QICs" = qics,
    "models" = gee_model
    )

  return(return_data)
}
```

### Original Clusters and Original COVID-19 Rate

Calculate GEE models with: - Clustering: SaTScan cluster centers & State ID - Dependent variable: original COVID-19 incidence (including errors).

```{r gee-original-clusters-original-incidence}
gee_or_clus_ordep <- gee_data %>% onegee(
                    dep_var = "or_incidence",
                    id = gee_data$ss_clusID,
                    term_names = table2$term)
gee_or_clus_ordep$coefficients %>%
  kable(caption = "Original Cluster IDs and Original COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### Original Clusters and Corrected COVID-19 Rate

Calculate GEE models with: - Clustering: SaTScan cluster centers & State ID - Dependent variable: reproduced COVID-19 incidence (corrected errors).

```{r gee-original-clusters-reproduced-incidence}
gee_or_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$ss_clusID,
                    term_names = table2$term)
gee_or_clus_rpdep$coefficients %>%
  kable(caption = "Original Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### GINI Clusters and Fixed COVID-19 Rate

Calculate GEE models with: - Clustering: Reproduced SaTScan GEE clusters & State ID - Dependent variable: reproduced COVID-19 incidence (fixed errors).

```{r gee-gini-clusters-reproduced-incidence}
gee_gini_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$gini_clusID,
                    term_names = table2$term)
gee_gini_clus_rpdep$coefficients %>%
  kable(caption = "Reproduced SaTScan GINI Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### SpatialEpi Clusters and Fixed COVID-19 Rate

Calculate GEE models with: - Clustering: Reproduced SpatialEpi clusters & State ID - Dependent variable: reproduced COVID-19 incidence (fixed errors).

```{r gee-spatialepi-clusters-reproduced-incidence}
gee_rp_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$rp_clusID,
                    term_names = table2$term)
gee_rp_clus_rpdep$coefficients %>%
  kable(caption = "Reproduced SpatialEpi Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### Compare GEE results

**Unplanned deviation for reanalysis**: Generate dot-and-whisker plot of coefficients for each of the model variations for efficient visual comparison of coefficients across each model.

```{r dotwhisker-comparison, message=FALSE}
# create summary data frame compatible with dotwhisker package functions
# starting with original study results
t2whisker <- table2 %>%
  mutate(model = "Original Study") %>%
  select(-c(starts_with("row"), "wald_chi_square", "p_stars"))

geewhisker <- bind_rows(
  mutate(gee_or_clus_ordep$coefficients,
         model = "Switch to R Geepack"),
  mutate(gee_or_clus_rpdep$coefficients,
         model = "Correct COVID Incidence"),
  mutate(gee_gini_clus_rpdep$coefficients,
         model = "SaTScan GINI-Optimized Clusters"),
  mutate(gee_rp_clus_rpdep$coefficients,
         model = "SpatialEpi Clusters")) %>%
  select(1:5, "model")

geewhisker <- bind_rows(t2whisker, geewhisker) %>%
  filter(!grepl("intercept", term))

# generate create dot whisker plot
geewhisker_fig <- geewhisker %>%
  dwplot(dodge_size = 0.6,
         vline = geom_vline(
           xintercept = 0,
           colour = "grey60",
           linetype = 2
       )) +
    scale_colour_brewer(type = "div",
                        palette = "RdYlBu",
                        name = "Model Variations") +
    theme_bw() +
    xlab("Coefficient")

geewhisker_fig

rm(t2whisker)
```

The figure above presents five variations of the original model, beginning with the results reported in the initial study. The first two modified models make incremental changes that align closely with the objectives of a reproduction study. The most substantial differences arose from a change in computational environment—from SPSS to the *geepack* package in R—which significantly altered coefficient magnitudes. Notably, the positive coefficient for Hispanic individuals dropped below its original confidence interval, while the negative coefficients for "Above poverty level" and "Male" increased to the outer bounds of their original intervals. In contrast, correcting a known error in COVID-19 incidence rates for 13 counties had minimal impact on the coefficient estimates.

More substantial reanalyses involved redefining COVID-19 clusters—first using all counties in the SaTScan GINI-Optimized clusters and then using counties from the SpatialEpi clusters. These revisions further reduced the size of most coefficients, likely due to improved spatial dependence control. The most notable changes occurred in the Ethnicity model, where the Hispanic and Non-Hispanic White coefficients fell beyond their original confidence intervals, and the Hispanic coefficient lost statistical significance. The "Above poverty level" and "Male" coefficients also increased beyond their initial confidence bounds. Despite these shifts, several coefficients remained robust and significant across all changes, including those for Black, Native American, Non-Hispanic non-White, Below poverty level, and Female individuals—groups associated with greater vulnerability. Meanwhile, consistently negative coefficients for White, Non-Hispanic White, Above poverty level, and Male individuals suggest intersections with less vulnerable identities. Interestingly, both coefficients for elderly individuals with disabilities also remained robustly negative, contrary to expectations.


### Interpret GEE Model

```{r residuals}
# create data frame with residuals
gee_resid <- data.frame(
  select(gee_or_clus_rpdep$models[[1]]$data, covid_rate, ss_clusID),
  data.frame(fitvals = gee_or_clus_rpdep$models[[1]]$fitted.values),
  data.frame(residual = gee_or_clus_rpdep$models[[1]]$residual),
  data.frame(working = residuals(gee_or_clus_rpdep$models[[1]], type = "working")),
  data.frame(response = residuals(gee_or_clus_rpdep$models[[1]], type = "response")),
  data.frame(pearson = residuals(gee_or_clus_rpdep$models[[1]], type = "pearson"))
) %>%
  mutate(
    my_working = (covid_rate - fitvals) / fitvals,
    my_pearson = response * (sqrt(gee_or_clus_rpdep$models[[1]]$prior.weights)) / sqrt(fitvals^2)
  ) %>%
  st_sf()

# working residual is the model residual (r) from gee, BUT HOW IS THIS CALCULATED?
# it is not simply the response residual normalized by the fitted value as the
# datascienceblog suggests
# response residual is: y(observed value) - fitted value
# my working residual normalizes response residual by fitted value, and effectively
# the code version of pearsons does the same because the prior weights are all 1
# if the datascienceblog is correct, the code pearson's residual should be divided by the square root of the fitted value.
# code: https://github.com/cran/geepack/blob/master/R/geeglm.R
# blog: https://www.datascienceblog.net/post/machine-learning/interpreting_generalized_linear_models
```

```{r map-residuals}
tm_gee_residuals <- tm_shape(gee_resid) +
  tm_polygons("response",
    title = "Race Model Residuals",
    style = "equal",
    n = 7,
    border.alpha = .2,
    lwd = 0.2,
    palette = "RdBu",
    legend.hist = FALSE,
    midpoint = 0
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5,
    legend.width = 0.25,
    legend.hist.size = 0.5,
    legend.hist.height = 0.15
  )

tm_gee_residuals
```

Calculate variance, covariance, correlation, and weights

```{r weights}
# calculate k number of observations per cluster
gee_resid <- gee_resid %>%
  group_by(ss_clusID) %>%
  mutate(k = n()) %>%
  ungroup()

grps <- gee_resid %>% st_drop_geometry() %>% select(ss_clusID, residual = residual)

# create mask matrix
n <- length(gee_resid$ss_clusID)
# m <- matrix(nrow = n, ncol = n)

# this is very inefficient, but this makes matrix of equal clusID's:
# just need to omit the bottom-left of matrix and the diagonal
# selecting for rows 80-90 to help w debugging
m <- (outer(grps$ss_clusID, grps$ss_clusID, "==") &
  outer(rownames(grps), rownames(grps), "<"))

# calculate denominators
covar_d <- sum(m, na.rm = TRUE) - 1

# variance
v <- sum(grps$residual^2) / (n - 1)
# covariance
c <- sum(outer(grps$residual, grps$residual, "*") * m, na.rm = TRUE) / covar_d
# correlation
r <- c / v

# calculate weights
gee_resid <- gee_resid %>%
  mutate(w = 1 / (1 + (k - 1) * r))
```

Map each county's weight in GEE model.

```{r map-weights}
tm_gee_weights <- tm_shape(gee_resid) +
  tm_polygons("w",
    title = "Race Model Weights",
    style = "jenks",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    legend.hist = FALSE,
    midpoint = 0
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5,
    legend.width = 0.25,
    legend.hist.size = 0.5,
    legend.hist.height = 0.15
  )

tm_gee_weights

# re
```

```{r save-figures, eval = F}
# save figures as image files
# obviously this could be made into a for loop
# add height, width, and dpi parameters to tmap_save to meet criteria for particular publications.
tmap_options(unit = "in")
tmap_save(tm_author_clusters, here("results", "figures", "tm_author_clusters.png"))
tmap_save(tm_covid_rates, here("results", "figures", "tm_covid_rates.png"))
tmap_save(tm_disability_rates, here("results", "figures", "tm_disability_rates.png"))
tmap_save(tm_spatialepi_clusters, here("results", "figures", "tm_spatialepi_clusters.png"))
tmap_save(tm_spatialepi_gini, here("results", "figures", "tm_spatialepi_gini.png"))
tmap_save(tm_spatialepi_hier, here("results", "figures", "tm_spatialepi_hier.png"))
tmap_save(tm_spatialepi_cluster_risk_class, here("results", "figures", "tm_spatialepi_cluster_risk_class.png"))
tmap_save(tm_spatialepi_local_risk_class, here("results", "figures", "tm_spatialepi_local_risk_class.png"))
ggsave(here("results", "figures", "plot_coefficients.png"), geewhisker_fig)
```

# Discussion

## Bias and threats to validity

Given the research design and primary data to be collected and/or secondary data to be used, discuss common threats to validity and the approach to mitigating those threats, with an emphasis on geographic threats to validity.

**Edge effects** were not accounted for in the analysis.

The analysis created **spatial subgroups** based on **spatial clustering**.
The purpose of this grouping was to control for **spatial heterogeneity** between regions (defined as states) and **spatial correlation** within regions using GEE models.
The spatial subgroups based on state and COVID-19 risk were specified in the attribute transformation subsection above.

This analysis accounted for **first order spatial effects** of regional difference by including states in the clustering criteria for GEE models.
The analysis accounted for some **second order spatial effects** by including a relative risk score for COVID-19 spatial clusters in the clustering criteria for GEE models.
The analysis did not account for **spatial anisotropies**, as the Kulldorff spatial scan statistic was constrained to circular non-directional clusters.

The study used a cross-sectional design, aggregating cases across the full **temporal extent** from 1/22/2020-8/1/2020.
The **temporal support** was inconsequential, as both the COVID-19 cases and disability sociodemographic data were aggregated across time for the full temporal extent.
**Temporal effects** were not conceptualized, measured, or accounted for.
There is potential for error and uncertainty in areas experiencing rapid socio-demographic change due to the **temporal coverage** of the socio-demographic data, as it was derived from ACS estimates from 2014 to 2018, prior to the onset of the COVID-19 pandemic.

There was no documentation of any **data exclusion** based on attribute criteria in the original study.
No **outliers** were analyzed or accounted for in the study.
No **weights** were applied in the study.

## Unplanned deviations




